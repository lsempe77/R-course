---
title: "Randomized Assignment"
subtitle: "Econometrics with R"
author: "Dr. Lucas Sempé"
always_allow_html: yes
format: 
  pptx:
    incremental: true  
  revealjs:
    theme: [clean.scss]
    slide-number: true
    code-fold: false
    highlight-style: github
editor_options: 
  chunk_output_type: console
---
## Randomized Assignment: The Gold Standard

:::: {.columns}

::: {.column width="60%"}
- **Core idea**: Randomly select who receives the treatment
- **Result**: Treatment and control groups are statistically identical (in expectation)
- **Advantage**: Differences in outcomes can be attributed to the program
- **Why it works**: Randomization creates a valid counterfactual
- **Types**: Encouragement, lottery, phase-in, etc.
:::

::: {.column width="40%"}
```{r, echo=FALSE, fig.height=12}
library(broom)
library(estimatr)
library(fishmethods)
library(haven)
library(kableExtra)
library(modelsummary)
library(tidyverse)
library(flextable)

set.seed(123)

# Create data
n <- 100
data <- data.frame(
  id = 1:n,
  potential_outcome = rnorm(n, mean = 50, sd = 10)
)

# Randomly assign treatment
data$treatment <- sample(c(0, 1), n, replace = TRUE)

# Add some treatment effect
data$actual_outcome <- data$potential_outcome + data$treatment * 10 + rnorm(n, 0, 2)

# Plot
ggplot(data, aes(x = treatment, y = actual_outcome, group = treatment)) +
  geom_jitter(width = 0.1, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 4, color = "red") +
  stat_summary(fun = mean, geom = "line", aes(group = 1), color = "red") +
  labs(title = "Treatment Effect with Random Assignment",
       x = "Treatment Status",
       y = "Outcome") +
  scale_x_continuous(breaks = c(0, 1), labels = c("Control", "Treatment")) +
  theme_minimal()
```
:::

::::

## Why Does Randomization Work? How Does it Create a Valid Counterfactual?

Let's think through an example. 

- If we randomly choose two people from this room, they will likely have very different characteristics (observable ones such as age, sex, education, and unobservable ones such as innate abilities, motivation, ideas, etc.). **They may not have anything in common at all. They would not make good counterfactuals for each other.**

- However, something different happens when we randomly choose large groups of people. If we were to randomly choose two groups of 1,000 people from across the country, with every person having an equal chance of being chosen, these groups will, *on average*, have statistically equivalent characteristics. If you remember from statistics class, **a random sample represents the population from which it is drawn.** Therefore, two large random samples will have statistically equivalent characteristics that represent the population from which they were drawn. We would expect these groups to have:
  - Approximately the same average age, sex composition, average level of educational attainment, same average income
  - And they will be approximately equal in characteristics we can’t directly observe or measure: approximately the same ability, the same motivation, etc. 

- Any slight differences will be statistically insignificant

**In short:**
- **If groups are big enough and random assignment is used, the groups will be equivalent on average, even on characteristics we cannot observe.**

## Implementing Randomized Assignment

1. Define population of eligible units
2. Decide on level of randomization (individuals, households, villages)
3. Determine sample size (power calculations)
4. Randomly select units to receive treatment
5. Verify balance between treatment and control groups
6. Implement program and collect data

## Fictional Case Study: Randomized Neighborhoods

- Program was implemented as a pilot in 100 neighborhoods randomly selected from all neighborhoods
- 100 additional randomly selected neighborhoods serve as controls
- This design ensures that treatment and control neighborhoods are statistically identical
- Only businesses below certain degree of efficiency in treatment neighborhoods were eligible

## Verifying Balance at Baseline

```{r, echo=F}
df <- read.csv("./evaluation_data_GreenWaste.csv")

```

:::: {.columns}
::: {.column width="60%"}
- Results show most characteristics are balanced
- Small differences in education of business manager and distance to recycling centre
- With many characteristics, some differences by chance are expected

```{r, eval=T, echo=F}
# Check if treatment and control are balanced at baseline

m <- df %>%
  filter(round == 0, eligible == 1) %>%
  select(treatment_neighborhood, age_manager, age_deputy,
         educ_manager, educ_deputy,
         female_manager, foreign_owned, staff_size,
         advanced_filtration, water_treatment_system,
         business_area, recycling_center_distance) %>%
  pivot_longer(-c("treatment_neighborhood")) %>%
  group_by(name) %>%
  do(tidy(lm_robust(value ~ treatment_neighborhood, data = .))) %>%
  filter(term == "treatment_neighborhood") %>%
  mutate(name = recode(name,
                       "age_manager" = "Manager Age",
                       "age_deputy" = "Deputy Age",
                       "educ_manager" = "Manager Education",
                       "educ_deputy" = "Deputy Education",
                       "female_manager" = "Female Manager",
                       "foreign_owned" = "Foreign Owned",
                       "staff_size" = "Staff Size",
                       "advanced_filtration" = "Advanced Filtration",
                       "water_treatment_system" = "Water Treatment System",
                       "business_area" = "Business Area",
                       "recycling_center_distance" = "Distance from Nearest Recycling Center"
  )) %>%
  select(name, estimate, std.error, p.value) %>%
  mutate(across(c(estimate, std.error, p.value), ~ round(.x,2))) %>%
  rename(Variable = name,
         Estimate = estimate,
         `SE` = std.error,
         `P-val` = p.value)

```

```{r}

# kable(m) %>% scroll_box(width = "600px", height = "400px")

m %>% kable(
    format = "html",
    booktabs = TRUE,
    caption = "<center><span style='font-size:20px; color: black; font-weight: bold;'>Diff in Treat and Control Baseline Characteristics</span></center>",
    col.names = c(
      "Variable",
      "Diff Treat/Control",
      "Std. Error",
      "P-value"
    ),
    align = c("l", "c", "c", "c"),
    escape = FALSE
  ) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed"),
    position = "left"
  )


## Output for case study
# library(officer)
# 
# # m is your data.frame with 4 columns:
# # "Variable", "Diff Treat/Control", "Std. Error", "P-value"
# 
# ft <- flextable(m)
# 
# ## Alignments like kable(align = c("l","c","c","c"))
# ft <- align(ft, j = 1, align = "left",   part = "all")
# ft <- align(ft, j = 2:4, align = "center", part = "all")
# 
# ## Booktabs-style horizontal rules + alternating row stripes
# ft <- theme_booktabs(ft)
# ft <- bg(ft, i = seq_len(nrow(m)) %% 2 == 0, bg = "#F7F7F7", part = "body")
# 
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9) 
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# # optional: a bit of breathing room
# # ft <- padding(ft, padding = 2)
# 
# ## Optional: Save to Word (.docx)
# doc <- read_docx()
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session6_RCT_baseline.docx")

```

:::

::: {.column width="40%"}

```{r, eval=F, echo=TRUE}
#| class: small-code
# Check if treatment and control groups are balanced at baseline

# Step 1: Filter to only keep baseline (pre-intervention) observations
# Step 2: Select relevant baseline variables to test for balance
# Step 3: Reshape data to long format using pivot_longer() so that we have one row per variable per business, keeping treatment assignment
# Step 4: Group by each baseline variable
# Step 5: For each variable, run a simple regression of the baseline variable on treat assignment 
# Step 6: Only keep the coefficient for 'treatment_neighborhood' since we are interested in differences between treatment and control
# Step 7: Select key results to display (variable name, estimated difference, standard error, and p-value)
df %>%
  filter(round == 0, eligible == 1) %>% 
  select(treatment_neighborhood, age_manager, age_deputy,
         educ_manager, educ_deputy, 
         female_manager, foreign_owned, staff_size,
         advanced_filtration, water_treatment_system, 
         business_area, recycling_center_distance) %>%
  pivot_longer(-c("treatment_neighborhood")) %>%
  group_by(name) %>%
  do(tidy(lm_robust(value ~ treatment_neighborhood, data = .))) %>%
  filter(term == "treatment_neighborhood") %>%
  select(name, estimate, std.error, p.value)
```
:::
::::

## Estimating Program Impact: Simple Comparison of Means
:::: {.columns}

::: {.column width="50%"}
```{r, eval=T, echo=TRUE}
#| class: small-code

# Compare waste expenditures in treatment and control neighborhoods at follow-up
# Regression at baseline: are waste expenditures different between treatment and control groups before intervention?
out_round0 <- lm_robust(waste_management_costs ~ treatment_neighborhood,
                        data = df %>% filter(round == 0 & eligible ==1),
                        clusters = neighborhood_identifier)

# Regression at follow-up: are waste expenditures different between treatment and control groups after intervention?
out_round1 <- lm_robust(waste_management_costs ~ treatment_neighborhood,
                        data = df %>% filter(round == 1 & eligible ==1),
                        clusters = neighborhood_identifier)
```
:::

::: {.column width="50%"}

```{r}

# Display the results side-by-side in a nice kable table: Compare estimates for Round 0 (baseline) and Round 1 (follow-up)

modelsummary(list("Round 0: Baseline"= out_round0, "Round 1: After"=out_round1), stars = TRUE, coef_map = c(
               "treatment_neighborhood" = "Treatment vs. Control",
               "(Intercept)" = "(Intercept)"),
             gof_map = c("nobs", "r.squared","adj.r.squared"), output = 'kableExtra') 
```

:::
::::

## Using Regression Analysis

:::: {.columns}

::: {.column width=50%"}
```{r, eval=T, echo=TRUE}
#| class: small-code

# Compare waste expenditures in T and C neighborhoods at follow-up with additional covariates
out_round2 <- lm_robust(waste_management_costs ~ treatment_neighborhood +
                    age_manager + age_deputy +
                    female_manager + foreign_owned + 
                    staff_size +
                    advanced_filtration + business_area +
                    recycling_center_distance,
                    data = df %>% filter(round == 1 & eligible ==1),
                    clusters = neighborhood_identifier)
```
:::

::: {.column width="50%"}

```{r}
#| class: small-code

# Display results in a table 

modelsummary(
  list("Model 1: No covariate adj." = out_round1,
       "Model 2: With covariate adj." = out_round2),
  coef_rename = c("treatment_neighborhood" = "Treat vs. Control Effect"), # rename only
  stars = TRUE,
  gof_map = c("nobs", "r.squared", "adj.r.squared"),
  title = "RCT Regression Results",
  output = "kableExtra"
) |>
  kable_styling(font_size = 13) |>
  scroll_box(width = "600px", height = "300px")



```

```{r}

# Simplified version with just no cov adjustment

# Build the table as a flextable (editable in Word/PowerPoint)
# ft <- modelsummary(
#   list("RCT" = out_round1),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "RCT Regression Results",
#   coef_map = c(
#     "treatment_neighborhood" = "RCT Effect",
#     "(Intercept)" = "(Intercept)"
#   ),
#   notes = "Standard errors are in parentheses",
#   fmt = 2,
#   output = "flextable"
# )
#
# # Optional: Save to word doc
# library(officer)
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# # optional: a bit of breathing room
# # ft <- padding(ft, padding = 2)
# 
# ## 1) Save to Word (.docx)
# doc <- read_docx()
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session6_RCT.docx")

```  

- Treatment effect remains stable with addition of control variables
- Controls improve precision (smaller standard errors)
- Adding controls increases R² from 0.30 to 0.43

:::
::::

## Why Covariates Don't Change the Estimate Much

In randomized experiments:

1. Treatment assignment is independent of observed and unobserved characteristics
2. Control variables are uncorrelated with treatment status (in expectation)
3. Including controls may:
   - Increase precision (reduce standard errors)
   - Account for any chance imbalances
   - But should not substantially change the point estimate

## Visualizing the Results

:::: {.columns}

::: {.column width=50%"}

```{r, eval = F, echo=T}
#| class: small-code

# Step 1: Group the data by offer status (treatment vs. control) and round (before vs. after)
# Step 2: Relabel variables to make the plot labels easier to understand ("0" becomes "Control" or "Before", "1" becomes "Treatment" or "After")
# Step 3: Summarize the data by calculating the average waste management cost for each group and time period
# Step 4: Plot the average costs over time, drawing separate lines for treatment and control groups
#Step 5: Customize the plot with titles, axis labels, colors, and a clean minimal theme

df %>% group_by(intent_to_treat, round) %>% 
  mutate(intent_to_treat = recode(as.factor(intent_to_treat), `0` = "Control", `1` = "Treatment"),
             round = recode(as.factor(round), `0` = "Before", `1` = "After")) %>%
  summarise(waste_management_costs = mean(waste_management_costs)) %>%
  ggplot(aes(x = round, y = waste_management_costs, group = intent_to_treat, color = intent_to_treat)) +
  geom_line(size = 1.2) + geom_point(size = 3) +
  labs(title = "Program Impact on Waste Expenditures", x = "Round",
       y = "Waste Expenditures (AED)") +
  theme_minimal() +  theme(legend.position = "bottom")

```

:::

::: {.column width=50%"}

```{r, echo=F, fig.height=7}
#| class: small-code

df %>% group_by(intent_to_treat, round) %>% 
  mutate(intent_to_treat = recode(as.factor(intent_to_treat), `0` = "Control", `1` = "Treatment"),
             round = recode(as.factor(round), `0` = "Before", `1` = "After")) %>%
  summarise(waste_management_costs = mean(waste_management_costs)) %>%
  ggplot(aes(x = round, y = waste_management_costs, group = intent_to_treat, color = intent_to_treat)) +
  geom_line(size = 1.2) + geom_point(size = 3) +
  labs(title = "Program Impact on Waste Expenditures", x = "Round",
       y = "Waste Expenditures (AED)") +
  theme_minimal() +  theme(legend.position = "bottom")

```

- Closer baseline values confirm balance between groups
- Clear divergence after the program
- Treatment group shows significant reduction in expenditures
- Control group shows slight increase over time

:::

::::
## Strength of the Results

- **Internal validity**: Strong - randomization ensures that the impact is attributable to the program
- **External validity**: Limited to similar contexts
- **Precision**: High - narrow confidence intervals
- **Policy relevance**: Impact exceeds the 1,000 AED threshold

## From Analysis to Policy Decision

**Policy question**: Should the Programe be scaled up nationally?

**Decision criterion**: Program must reduce waste expenditures by at least 1,000 Dirham.

**Results from randomized evaluation**:

- Impact: -1,014 (95% CI: [-1,930, -935])
- Exceeds threshold of 1,000 Dirham reduction

**Recommendation**: The program should be scaled up nationally.

## Limitations of Randomized Assignment

:::: {.columns}

::: {.column width="50%"}
1. **Ethical concerns**
   - Denying benefits to control group
   - Informed consent issues

2. **Practical challenges**
   - Political constraints
   - Implementation costs
   - Scale vs. pilot differences
:::

::: {.column width="50%"}
3. **Technical issues**
   - Spillover effects
   - Hawthorne effects
   - Attrition and non-compliance
   - External validity

4. **Timing**
   - Long-term outcomes
   - Delay in results for urgent policies
:::

::::


## Types of Randomization

Different types of randomization can help address some of the ethical and practical challenges. 

1. **Lottery**
   - Use random number generator to select eligible units to receive treatment.
   - Useful when there are insufficient resources to meet demand and is logistically simple.
   - Some eligible units do not receive treatment (control).

2. **Multiple Treatments**
   - Randomly assign units to different treatment arms.
   - Useful when we are interested in the comparative effectiveness of different intervention approaches or methods of service delivery. 
   - Complex to implement and requires even larger sample.

3. **Phase-in**
   - Randomly assign units to receive treatment at different times. 
   - Useful when we want all eligible units to receive treatment eventually, and can help us understand impact of program over time.
   - Susceptible to anticipation bias.
   
4. **Encouragement**
   - Treatment is randomly encouraged rather than assigned.
   - Useful when we want all units to have the option to receive treatment, and can help us understand if encouragement mechanisms improve outcomes.
   - Requires larger sample and assesses impact only for those that respond to encouragement. 
   - Instrumental variables, covered in the next session, is an example of this
   
   
## When Randomization Isn't Possible

When randomization is not feasible, we can use quasi-experimental methods:

1. **Instrumental Variables**: Using random encouragement
2. **Regression Discontinuity**: Exploiting eligibility thresholds
3. **Difference-in-Differences**: Comparing changes over time
4. **Matching Methods**: Creating comparable groups

## Key Takeaways

1. Randomization creates comparable treatment and control groups
2. With randomization, differences in outcomes can be attributed to the program
3. Including covariates doesn't substantially change estimates but can improve precision
4. The program reduces waste expenditures by 1,014 AED, exceeding the threshold
5. Based on the randomized evaluation, GreenWaste should be scaled up nationally

## Next Session

**Instrumental Variables**: Leveraging randomized assignment to evaluate programs with imperfect compliance