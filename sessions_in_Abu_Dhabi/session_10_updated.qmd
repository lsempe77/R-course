---
title: "Matching Methods"
subtitle: "Econometrics with R"
author: "Dr. Lucas Sempé"
always_allow_html: yes
format:
  pptx:
    incremental: true  
  revealjs:
    theme: [clean.scss]
    slide-number: true
    code-fold: false
    highlight-style: github
editor_options: 
  chunk_output_type: console
---

## Matching Methods: Overview

:::: {.columns}

::: {.column width="60%"}
- **Core idea**: Create comparable treatment and control groups based on observable characteristics
- **Setting**: When treatment assignment is related to observable factors
- **Advantage**: Reduces selection bias from observable differences
- **Assumption**: No unobserved differences affecting both treatment and outcomes
- **Types**: Exact matching, propensity score matching, nearest neighbor, etc.
:::

::: {.column width="40%"}
```{r, echo=FALSE, fig.height=4}

# Load required packages
library(tidyverse)
library(MatchIt)
library(estimatr)
library(kableExtra)
library(modelsummary)

# Set rendering options
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  fig.width = 10, 
  fig.height = 6
)

set.seed(123)

df <- read.csv("./evaluation_data_GreenWaste.csv")

# Create simulated data for matching visualization
set.seed(123)
n <- 200

# Create two variables that predict both treatment and outcome
x1 <- runif(n, -2, 2)
x2 <- runif(n, -2, 2)

# Generate treatment with higher probability for larger x1, x2
p_treat <- plogis(0.5 + 0.7*x1 + 0.7*x2)
treatment <- rbinom(n, 1, p_treat)

# Create data frame
matching_data <- data.frame(
  x1 = x1,
  x2 = x2,
  treatment = factor(treatment, labels = c("Control", "Treatment"))
)

# Plot
ggplot(matching_data, aes(x = x1, y = x2, color = treatment, shape = treatment)) +
  geom_point(size = 2) +
  labs(title = "Before Matching: Imbalanced Groups",
       x = "Variable X1",
       y = "Variable X2",
       color = "Group",
       shape = "Group") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
:::

::::

## Why Matching?


**Problem**: Selection bias

- Treatment group systematically differs from control group
- Direct comparison leads to biased impact estimates

**Solution**: Matching

- Select control units similar to treated units
- Create balance on observable characteristics
- Approximates an experimental setting

## Preparing the Data

Converting from long to wide format:

```{r}
# Create a wide-format dataset
df_w <- df %>%
  # Then create wide format
  pivot_wider(
    id_cols = c(neighborhood_identifier, business_identifier, treatment_neighborhood, 
                eligible, intent_to_treat, enrolled_rp),
    names_from = round, # variable that determines new columns
    # variables that should be made "wide"
    values_from = c(waste_management_costs, 
                    efficiency_index, age_manager, age_deputy,
                    educ_manager, educ_deputy, female_manager,
                    foreign_owned, staff_size, advanced_filtration,
                    water_treatment_system, business_area,
                    recycling_center_distance, recycling_compliance)) %>%
  # remove the business that has missing values
  # as missing values are not allowed when using matchit
  filter(!is.na(waste_management_costs_0)) 

# Also check the first few rows to confirm format
head(select(df_w, business_identifier, intent_to_treat, 
           waste_management_costs_0, waste_management_costs_1))
```

## Propensity Score Matching (PSM)

Propensity Score Matching (PSM) is when we predict the probability of each unit receiving treatment and then compare those with similar propensity scores. There are two scenarios for predicting enrollment:

1. **Limited set of variables**:
   - Only age and education of business manager

2. **Full set of variables**:
   - All available baseline characteristics

## Estimating Propensity Scores

```{r}
## Manually trim to 5–95% common range 
# discard = "both" trims data to area of common support
# then we manually trim it to the 5-95% range and re-run matchit


## ----- LIMITED SET -----
# Fit PS & discard non-overlap
psm_r0 <- matchit(
  intent_to_treat ~ age_manager_0 + educ_manager_0,
  data = df_w %>% dplyr::select(-recycling_compliance_0, -recycling_compliance_1),
  distance = "glm", link = "probit", discard = "both", method = "nearest", estimand = "ATT"
)

# 5–95% common-range trimming
df_tmp_r <- df_w %>% mutate(ps = psm_r0$distance, treat = intent_to_treat == 1)
lower_r <- max(quantile(df_tmp_r$ps[df_tmp_r$treat], 0.05, na.rm = TRUE),
               quantile(df_tmp_r$ps[!df_tmp_r$treat], 0.05, na.rm = TRUE))
upper_r <- min(quantile(df_tmp_r$ps[df_tmp_r$treat], 0.95, na.rm = TRUE),
               quantile(df_tmp_r$ps[!df_tmp_r$treat], 0.95, na.rm = TRUE))
df_trim_r <- dplyr::filter(df_tmp_r, ps >= lower_r & ps <= upper_r)

# Re-run matchit on the trimmed data
psm_r <- matchit(
  intent_to_treat ~ age_manager_0 + educ_manager_0,
  data = df_trim_r %>% dplyr::select(-recycling_compliance_0, -recycling_compliance_1, -ps, -treat),
  distance = "glm", link = "probit", discard = "both", method = "nearest", estimand = "ATT"
)

## ----- FULL SET -----
psm_ur0 <- matchit(
  intent_to_treat ~ age_manager_0 + educ_manager_0 +
    age_deputy_0 + educ_deputy_0 + female_manager_0 + foreign_owned_0 +
    staff_size_0 + advanced_filtration_0 + water_treatment_system_0 +
    business_area_0 + recycling_center_distance_0,
  data = df_w %>% dplyr::select(-recycling_compliance_0, -recycling_compliance_1),
  distance = "glm", link = "probit", discard = "both", method = "nearest", estimand = "ATT"
)

df_tmp <- df_w %>% mutate(ps = psm_ur0$distance, treat = intent_to_treat == 1)
lower <- max(quantile(df_tmp$ps[df_tmp$treat], 0.05, na.rm = TRUE),
             quantile(df_tmp$ps[!df_tmp$treat], 0.05, na.rm = TRUE))
upper <- min(quantile(df_tmp$ps[df_tmp$treat], 0.95, na.rm = TRUE),
             quantile(df_tmp$ps[!df_tmp$treat], 0.95, na.rm = TRUE))
df_trim <- dplyr::filter(df_tmp, ps >= lower & ps <= upper)

psm_ur <- matchit(
  intent_to_treat ~ age_manager_0 + educ_manager_0 +
    age_deputy_0 + educ_deputy_0 + female_manager_0 + foreign_owned_0 +
    staff_size_0 + advanced_filtration_0 + water_treatment_system_0 +
    business_area_0 + recycling_center_distance_0,
  data = df_trim %>% dplyr::select(-recycling_compliance_0, -recycling_compliance_1, -ps, -treat),
  distance = "glm", link = "probit", discard = "both", method = "nearest", estimand = "ATT"
)
```


## Propensity Score Models

```{r}
# Create a model summary table
modelsummary(list("Limited Set" = psm_r$model, 
                  "Full Set" = psm_ur$model),
             coef_map = c('age_manager_0' = "Age (Manager) at Baseline",
                          'educ_manager_0' = "Education (Manager) at Baseline",
                          'age_deputy_0' = "Age (Deputy) at Baseline",
                          'educ_deputy_0' = "Education (Deputy) at Baseline",
                          'female_manager_0' = "Female Manager at Baseline",
                          'foreign_owned_0' = "Foreign Owned at Baseline",
                          'staff_size_0' = "Number of Staff at Baseline",
                          'advanced_filtration_0' = "Advanced Filtration at Baseline",
                          'water_treatment_system_0' = "Water Treatment System at Baseline",
                          'business_area_0' = "Business Area at Baseline",
                          'recycling_center_distance_0' = "Distance From Recycling Center"),
             title = "Estimating the Propensity Score Based on Baseline Characteristics")
```

## Interpreting the Propensity Score Models

- Which characteristics predict program enrollment?
- Are facilities with certain characteristics more likely to enroll?
- Does this align with program objectives?

## Checking Common Support

Let's plot the distribution of propensity scores by enrollment status:

```{r}
# Add propensity scores to our dataset
df_w <- df_w %>%
  mutate(ps_ur0 = psm_ur0$model$fitted.values)

# Plot the distribution
df_w %>%
  mutate(intent_to_treat_lab = ifelse(intent_to_treat == 1, "Offered", "Not Offered")) %>%
  ggplot(aes(x = ps_ur0,
             group = intent_to_treat_lab, colour = intent_to_treat_lab, fill = intent_to_treat_lab)) +
  geom_density(alpha = 0.2) +
  xlab("Propensity Score") +
  labs(title = "Distribution of Propensity Score by Offer Status") +
  scale_fill_viridis_d("Status:", end = 0.7) +
  scale_colour_viridis_d("Status:", end = 0.7) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## What is Common Support?

- **Common support** = overlap in propensity scores between groups
- Essential for valid comparisons
- Without common support, we can't find comparable units

## Checking Balance Before Matching

```{r}
kableExtra::kable(summary(psm_ur)$sum.all,
      caption = "Balance Before Matching") %>%
  kable_styling(font_size = 10)
```

## Checking Balance After Matching

```{r}
kableExtra::kable(summary(psm_ur)$sum.matched,
      caption = "Balance After Matching") %>%
  kable_styling(font_size = 10)
```

## Understanding Balance

- **Mean Diff** should be closer to zero after matching
- Standardized mean differences (not shown) should be < 0.25
- Good balance ensures we're comparing similar facilities

## Estimating Program Impact

First, extract the matched dataset:

```{r}
# Extract matched datasets
match_df_r <- match.data(psm_r, drop.unmatched = TRUE)   # Limited set
match_df_ur <- match.data(psm_ur, drop.unmatched = TRUE) # Full set
```

## Regression with Matched Data

```{r}
# Regression with matched data
out_lm_r <- lm_robust(waste_management_costs_1 ~ intent_to_treat,
                      data = match_df_r,  
                      clusters = neighborhood_identifier)

out_lm_ur <- lm_robust(waste_management_costs_1 ~ intent_to_treat,
                      data = match_df_ur, 
                      clusters = neighborhood_identifier)

# Show results
modelsummary(list("Limited Set" = out_lm_r, 
                  "Full Set" = out_lm_ur),
             title = "Impact on Waste Management Costs: Matching Approach")

```

```{r}

# # # Simplified version
# 
# library(tinytable)
# 
# modelsummary(
#   list("Limited Covs PSM" = out_lm_r, "All Covs PSM"= out_lm_ur),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "Matching Regression Results",
#   coef_map = c(
#     "intent_to_treat" = "Matching Effect",
#     "(Intercept)" = "(Intercept)"
#   ),
#   coef_omit = NULL,
#   notes = "Standard errors are in parenthesis",
#   output = "tinytable"
# ) |>
#   style_tt(bootstrap_class = "table caption-top")
# 
# ## Output for case study
# library(flextable)
# library(officer)
# 
# # Build the table as a flextable (editable in Word/PowerPoint)
# ft <- modelsummary(
#   list("Limited Covs PSM" = out_lm_r, "All Covs PSM"= out_lm_ur),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "Matching Regression Results",
#   coef_map = c(
#     "intent_to_treat" = "Matching Effect",
#     "(Intercept)" = "(Intercept)"
#   ),
#   notes = "Standard errors are in parentheses",
#   fmt = 2,
#   output = "flextable"
# )
# 
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# 
# ## 1) Save to Word (.docx)
# doc <- read_docx()
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session10_PSM.docx")

``` 

## Matched Difference-in-Differences

Combine matching with difference-in-differences:

```{r}
# Merge matching weights back into long format
df_long_match_r <- df %>%
  left_join(match_df_r %>% dplyr::select(business_identifier, weights)) %>%
  filter(!is.na(weights))

df_long_match_ur <- df %>%
  left_join(match_df_ur %>% dplyr::select(business_identifier, weights)) %>%
  filter(!is.na(weights))
```

## Difference-in-Differences Results

```{r}
# Run DiD regression
did_reg_r <- lm_robust(waste_management_costs ~ intent_to_treat * round,
                        data = df_long_match_r, weights = weights,
                        clusters = neighborhood_identifier)

did_reg_ur <- lm_robust(waste_management_costs ~ intent_to_treat * round,
                        data = df_long_match_ur, weights = weights,
                        clusters = neighborhood_identifier)

# Show results
modelsummary(list("Limited Set" = did_reg_r, 
                  "Full Set" = did_reg_ur),
             coef_map = c('intent_to_treat' = "Offered",
                          'round' = "Round",
                          'intent_to_treat:round' = "Offered × Round"),
             title = "Impact on Waste Management Costs: Matched DiD Approach")
```

## Interpretation of Results

- **Offered** coefficient: Baseline difference between groups offered program vs those not offered program
- **Round** coefficient: Time trend for all facilities
- **Offered × Round**: The program's causal effect

::: {.callout-note}
The interaction coefficient (Offered × Round) represents our estimate of the causal impact of the program on waste management costs.
:::

## Advantages of Matching

- Reduces selection bias
- Makes treatment and control groups comparable
- Can combine with difference-in-differences for robust estimation
- Works even without baseline randomization

## Limitations of Matching

- Only controls for **observed** variables
- Cannot account for unobserved confounders
- Requires good data on pre-treatment characteristics
- Common support may be limited in some contexts

## Summary

1. **Propensity Score Matching** helps create comparable groups
2. First **estimate propensity scores** based on baseline characteristics
3. Check for **common support** and **balance** after matching
4. Combine with **regression** or **difference-in-differences** to estimate impacts
5. Interpret results with appropriate caution about unobserved confounders

## Resources for Further Learning

- **Ho, Imai, King, and Stuart (2007)**: "Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference"
- **Stuart (2010)**: "Matching Methods for Causal Inference: A Review and a Look Forward"
- The **MatchIt** package documentation: [https://kosukeimai.github.io/MatchIt/](https://kosukeimai.github.io/MatchIt/)
- **"Mastering Metrics"** by Angrist and Pischke (Chapter 3)

## Thank You!


















<!-- ## Comparative Results Across Methods -->

<!-- ```{r, echo=FALSE, fig.height=4} -->
<!-- library(ggplot2) -->

<!-- # Create data frame with results from all methods -->
<!-- all_results <- data.frame( -->
<!--   Method = c("Randomized Assignment", "Instrumental Variables",  -->
<!--              "Regression Discontinuity", "Difference-in-Differences",  -->
<!--              "Matching (Full Set)"), -->
<!--   Estimate = c(-1014, -982, -905, -816, -1000), -->
<!--   CI_Lower = c(-1092, -1168, -992, -879, -1072), -->
<!--   CI_Upper = c(-935, -797, -818, -753, -927) -->
<!-- ) -->

<!-- # Sort by effect size -->
<!-- all_results <- all_results %>% -->
<!--   arrange(Estimate) -->

<!-- # Plot forest plot of results -->
<!-- ggplot(all_results, aes(y = reorder(Method, Estimate), x = Estimate)) + -->
<!--   geom_vline(xintercept = -1000, linetype = "dashed", color = "red") + -->
<!--   geom_point(size = 3) + -->
<!--   geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.3) + -->
<!--   labs(title = "Impact of GreenWaste on Waste Expenditures", -->
<!--        subtitle = "Comparison Across Evaluation Methods", -->
<!--        x = "Effect on Waste Expenditures (AED)", -->
<!--        y = "") + -->
<!--   theme_minimal() + -->
<!--   annotate("text", x = -1000, y = 5.5, label = "Threshold", color = "red", hjust = 1.2) -->
<!-- ``` -->

<!-- ## Final Policy Recommendation -->

<!-- - Methods produce consistent results in the range of -816 to -1033 AED -->
<!-- - Randomized assignment (gold standard): -1,014 AED -->
<!-- - Most quasi-experimental methods: Effect slightly below $10 -->
<!-- - Given uncertainty in estimates and consistency in direction, GreenWaste shows promising results -->

<!-- **RECOMMENDATION**: The preponderance of evidence suggests GreenWaste reduces waste expenditures by approximately $10, which meets the threshold criterion. Given the consistency across methods and the gold-standard randomized result, GreenWaste should be scaled up nationally. -->

<!-- ## Conclusion: Choosing the Right Method -->

<!-- | Method | When to Use | Key Assumption | Strengths | Limitations | -->
<!-- |--------|-------------|----------------|-----------|-------------| -->
<!-- | **Randomized** | Feasible to randomize | Random assignment | Gold standard; controls for all confounders | Implementation challenges; external validity | -->
<!-- | **IV** | Imperfect compliance; valid instrument exists | Exclusion restriction | Addresses selection; natural experiments | Local effect; requires strong instrument | -->
<!-- | **RDD** | Clear eligibility threshold | No manipulation of running variable | Addresses selection bias through psuedo-randomization | Local to threshold; requires threshold | -->
<!-- | **DiD** | Panel data; non-random assignment | Parallel trends | Controls for fixed differences and time trends | Cannot address time-varying confounders | -->
<!-- | **Matching** | Rich observational data | Selection on observables | Uses existing data; intuitive | Cannot address unobserved confounders | -->

<!-- ## Next Steps in Impact Evaluation -->

<!-- 1. **Heterogeneity analysis** -->
<!--    - Does impact vary across subgroups? -->
<!--    - Who benefits most from GreenWaste? -->

<!-- 2. **Cost-effectiveness analysis** -->
<!--    - Beyond impact, is GreenWaste cost-effective? -->
<!--    - How does it compare to alternative programs? -->

<!-- 3. **Implementation research** -->
<!--    - What factors affect successful implementation? -->
<!--    - How to optimize national scale-up? -->

<!-- 4. **Long-term follow-up** -->
<!--    - Do impacts persist over time? -->
<!--    - Are there additional benefits or unintended consequences? -->

<!-- ## Key Course Takeaways -->

<!-- 1. Impact evaluation requires identifying a valid counterfactual -->
<!-- 2. Randomized experiments provide the most credible counterfactual -->
<!-- 3. Quasi-experimental methods can provide rigorous evidence when randomization isn't possible -->
<!-- 4. Multiple methods with consistent results strengthen the evidence base -->
<!-- 5. Statistical significance must be paired with policy significance -->
<!-- 6. The choice of method depends on context, data, and research question -->
<!-- 7. R provides powerful tools for implementing all these methods -->

<!-- ## Thank You! -->

<!-- **Additional Resources**: -->

<!-- - Gertler, P. J., et al. (2016). *Impact Evaluation in Practice*, Second Edition. World Bank. -->
<!-- - Angrist, J. D., & Pischke, J. S. (2008). *Mostly Harmless Econometrics*. Princeton University Press. -->
<!-- - Cunningham, S. (2021). *Causal Inference: The Mixtape*. Yale University Press. -->
<!-- - R packages: `estimatr`, `MatchIt`, `rdrobust`, `did`, `fixest`, `AER` -->