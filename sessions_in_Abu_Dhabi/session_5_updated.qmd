---
title: "Introduction to Impact Evaluation"
subtitle: "Econometrics with R"
author: "Dr. Lucas Sempé"
always_allow_html: yes
format: 
  pptx:
    incremental: true  
  revealjs:
    theme: [clean.scss]
    slide-number: true
    code-fold: false
    highlight-style: github
---

## What is Impact Evaluation?

:::: {.columns}

::: {.column width="60%"}
- **Objective**: Measure causal effects of programs or policies
- **Challenge**: Identifying what would have happened without the intervention
- **Counterfactual**: The state of the world that would have occurred in absence of the intervention
- **Impact**: The difference between the actual outcome and the counterfactual
:::

::: {.column width="40%"}
```{r, echo=FALSE, fig.cap="Impact = Actual - Counterfactual", fig.height= 12}
library(broom)
library(estimatr)
library(fishmethods)
library(haven)
library(kableExtra)
library(modelsummary)
library(tidyverse)
library(flextable)

# Create example data

data <- data.frame(
  Time = c(0, 1, 0, 1),
  Outcome = c(14.5, 7.8, 14.5, 18),
  Group = c("Treatment", "Treatment", "Counterfactual", "Counterfactual")
)

# Create plot
ggplot(data, aes(x = Time, y = Outcome, color = Group, group = Group)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  annotate("segment", x = 1, xend = 1, y = 7.8, yend = 18, 
           arrow = arrow(length = unit(0.3, "cm")), linetype = "dashed") +
  annotate("text", x = 1.05, y = 13, label = "Impact", hjust = 0) +
  scale_x_continuous(breaks = c(0, 1), labels = c("Before", "After")) +
  labs(title = "Visualizing Impact", y = "Outcome", x = "") +
  theme_minimal()
```
:::

::::

## The Fundamental Problem of Causal Inference

> We cannot observe the same unit in both treatment and control states simultaneously.

- For each unit, we observe either:
  - The outcome with the intervention
  - The outcome without the intervention
- The challenge: How do we estimate the counterfactual?

## Example: Waste management system

- Government program subsidizing innovative waste management technologies 
- Goal: Reduce waste management costs
- Policy question: Should the program be scaled up nationally?
- Decision criterion: Program must reduce waste management costs by at least 1,000 Dirham per year

## Key Variables in Our Example Dataset

:::: {.columns}

::: {.column width="50%"}
**Outcome Variable**:

- `waste_management_costs`: Waste management costs incurred yearly per business (AED)

**Treatment Variables**:

- `treatment_neighborhood`: Neighborhood selected for program (0/1)
- `intent_to_treat`: Business offered the program (0/1)
- `eligible`: Business eligible for the program (0/1)
:::

::: {.column width="50%"}
**Other Variables**:

- `round`: Survey round (0=baseline, 1=follow-up)
- `efficiency_index`: Score based on various business characteristics
- Leadership Demographics: Age, education, gender, etc.
:::

::::

## Overview of Impact Evaluation Methods

**Experimental Methods**:

- Randomized assignment (gold standard)

**Quasi-Experimental Methods**:

- Instrumental Variables
- Regression Discontinuity
- Difference-in-Differences
- Matching Methods

## Naive Approaches to Estimating Impact

1. **Before-After Comparison**
   - Compare outcomes of beneficiaries before and after the program
   - Problem: Cannot distinguish program effects from other changes over time

2. **With-Without Comparison**
   - Compare beneficiaries to non-beneficiaries
   - Problem: Selection bias if those who receive the program are systematically different

## Before-After Comparison (Example)

```{r, echo=TRUE}
# Let's start by uploading our data.
# It is important to know in which folder your dataset is so you can use the right path.
# Set the working directory, if needed:
# setwd("path/to/your/directory")  # Uncomment and replace with your path

# Load in data
df <- read.csv("./evaluation_data_GreenWaste.csv")

```

```{r, eval=T, echo=TRUE}
# Compare waste management costs before and after for intent_to_treat (offered) businesses
# Fit a linear regression model using 'lm_robust' from the 'estimatr' package
# 'lm_robust' gives regression results with robust (heteroskedasticity-consistent) standard errors

# Formula: outcome variable ~ explanatory variable
# Clustered standard errors at the 'neighborhood_identifier' level
# Filter df to only run the regression on businesses in treatment neighborhoods AND intent_to_treat
m_ba1 <- lm_robust(waste_management_costs   ~ round, 
                  clusters = neighborhood_identifier,
                  data = df %>% dplyr::filter(treatment_neighborhood ==1 & intent_to_treat ==1))

```

```{r}

# # Just Before-After 
# library(officer)
# 
# # Build the table as a flextable (editable in Word/PowerPoint)
# ft <- modelsummary(
#   list("Before-After" = m_ba1),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "Before-After Regression Results",
#   coef_map = c(
#     "round" = "Before vs. After Effect",
#     "(Intercept)" = "(Intercept)"
#   ),
#   notes = "Standard errors are in parentheses",
#   fmt = 2,
#   output = "flextable"
# )
# 
# ft
#  
# # Optional: Save to word
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# # optional: a bit of breathing room
# # ft <- padding(ft, padding = 2)
# 
# # Save to Word (.docx)
# doc <- read_docx()
# # doc <- body_add_par(doc, "Before-After Regression Results", style = "heading 1")
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session5_before_after.docx")


```  

**Discussion**

- Is this effect due to the program? What are some other external factors that may cause a change in costs for waste management over time?

**Problems**: 

- External factors also change over time
- Cannot attribute all changes to the program

## With-Without Comparison (GreenWaste Example)

```{r, eval=T, echo=TRUE}
# Compare offered (intent_to_treat) vs. non-offered businesses after program implementation

# Use lm_robust as before, with clustered std errors
# This time, we filter df to run the regression on businesses in treatment neighborhoods AND after the intervention, in the follow-up survey round
m_ba2 <- lm_robust(waste_management_costs ~ intent_to_treat, 
                  clusters = neighborhood_identifier,
                  data = df %>% filter(treatment_neighborhood==1 & round ==1))

```

```{r}

# # Just With-Without Results
# # Build the table as a flextable (editable in Word/PowerPoint)
# ft <- modelsummary(
#   list("With-Without" = m_ba2),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "With-Without Regression Results",
#   coef_map = c(
#     "intent_to_treat" = "With vs. Without Program Effect",
#     "(Intercept)" = "(Intercept)"
#   ),
#   notes = "Standard errors are in parentheses",
#   fmt = 2,
#   output = "flextable"
# )
# 
# ft
# 
# Optional: Save to word
# library(officer)
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# # optional: a bit of breathing room
# # ft <- padding(ft, padding = 2)
# 
# # Save to Word (.docx)
# doc <- read_docx()
# # doc <- body_add_par(doc, "Before-After Regression Results", style = "heading 1")
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session5_with_without.docx")

```    

**Discussion**

- Are the enrolled businesses the same as those that were not enrolled in the program? How might they be different from one another?

**Problems**:

- Selection bias: Enrolled businesses differ from non-enrolled
- Cannot attribute all differences to the program

## Compare results

```{r}
  
ft <- modelsummary(list("Model 1: Before-After" = m_ba1, "Model 2: With-Without" = m_ba2),
             stars = TRUE,
             gof_map = c("nobs", "r.squared", "r2.adjusted"), 
             title = "Before-After vs. With-Without Regression Results",
             coef_map = c(
               "round" = "Before vs. After Effect",
               "intent_to_treat" = "With vs. Without Program Effect",
               "(Intercept)" = "(Intercept)")
             ,
             notes = "Standard errors are in parentheses",
             fmt = 2,
             output = "flextable"
             )

ft

# # Optional: Save to word
# library(officer)
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# 
# # Save to Word (.docx)
# doc <- read_docx()
# # doc <- body_add_par(doc, "Before-After Regression Results", style = "heading 1")
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session5_comparison.docx")

```      

## Conditions for Impact Evaluation

There are certain practical considerations and conditions that need to be met in order to conduct an impact evaluation. 

```{r, echo=FALSE}
library(knitr)

conditions_table <- data.frame(
  Condition = c(
    "Intervention",
    "Outcome(s)",
    "Problem Diagnosis",
    "Theory of Change",
    "Sufficient dose and duration",
    "Counterfactual",
    "Data Quality",
    "Data Sufficiency"
  ),
  Description = c(
    "The project, program or policy which is the subject of the impact evaluation. Should be clearly defined, with a known start time and duration as well as clearly defined eligibility criteria.",
    "One or more clearly defined, observable, and measurable outcomes of interest.",
    "A proposed program or intervention should be developed based on a sound analysis of a particular social or development need and the binding constraints and root causes (i.e., to ensure the solution matches the problem).",
    "A sound, well-constructed theory of change explaining expected causal pathways linking inputs, outputs, and outcomes, including a description and key assumptions associated with each causal step.",
    "The intervention should be of a sufficient scope, scale, and duration to theoretically produce the intended effect within the time frame of observation.",
    "A clearly defined hypothetical counterfactual, operationalized using a credible identification strategy.",
    "Reasonably accurate, complete data, with minimal or no systematic bias.",
    "Sufficient data to enable statistical comparison of outcomes between intervention and comparison groups."
  )
)

kable(
  conditions_table, 
  col.names = c("Condition", "Description"),
  caption = "Conditions for a Credible Impact Evaluation"
)
```

## Course Outline

1. **Introduction to Impact Evaluation** ← *You are here*
2. **Randomized Assignment**
3. **Instrumental Variables**
4. **Regression Discontinuity Designs**
5. **Difference-in-Differences** 
6. **Matching Methods**

## Key Takeaways

- Impact evaluation measures the causal effect of programs or policies
- The central challenge is estimating the counterfactual
- Naive before-after or with-without comparisons are susceptible to bias
- Various experimental and quasi-experimental methods address these challenges
- The example will illustrate these methods throughout the course

## Next Session

**Randomized Assignment**: The gold standard for causal inference

- How randomization creates comparable groups
- Implementing and analyzing randomized evaluations
- Interpreting results with confidence