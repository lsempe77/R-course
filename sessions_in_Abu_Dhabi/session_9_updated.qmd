---
title: "Difference-in-differences Design"
subtitle: "Econometrics with R"
author: "Dr. Lucas Sempé"
always_allow_html: yes
format: 
  pptx:
    incremental: true  
  revealjs:
    theme: [clean.scss]
    slide-number: true
    code-fold: false
    highlight-style: github
editor_options: 
  chunk_output_type: console
---

## Difference-in-Differences: Overview

:::: {.columns}

::: {.column width="60%"}
- **Core idea**: Compare changes over time between treated and untreated groups
- **Setting**: Panel or repeated cross-sectional data with pre/post periods
- **Advantage**: Controls for time-invariant differences between groups
- **Assumption**: Relies on "parallel trends" assumption
- **Applications**: Widely used for policy evaluation
- **Types**: Two-way fixed effects, staggered adoption, triple differences, matched DID, etc. 
:::

::: {.column width="40%"}
```{r, echo=FALSE, fig.height=4}
library(tidyverse)
library(estimatr)
library(kableExtra)
library(modelsummary)

set.seed(123)

df <- read.csv("./evaluation_data_GreenWaste.csv")

# Create data for DiD visualization
set.seed(123)
time_points <- c(0, 1)
treatment_group <- c(40, 30)
control_group <- c(50, 50)

# Create data frame
did_data <- data.frame(
  Time = rep(time_points, 2),
  Group = rep(c("Treatment", "Control"), each = 2),
  Outcome = c(treatment_group, control_group)
)

# Plot DiD
ggplot(did_data, aes(x = Time, y = Outcome, color = Group, group = Group)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_x_continuous(breaks = c(0, 1), labels = c("Before", "After")) +
  annotate("segment", x = 1, xend = 1, y = 30, yend = 50, 
           arrow = arrow(ends = "both", length = unit(0.1, "inches")), 
           linetype = "dashed") +
  annotate("text", x = 1.05, y = 40, label = "Treatment\nEffect") +
  labs(title = "Difference-in-Differences",
       y = "Outcome") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
:::

::::

## How DiD Works

Difference-in-Differences = (Treat<sub>After</sub> - Treat<sub>Before</sub>) - (Control<sub>After</sub> - Control<sub>Before</sub>)

:::: {.columns}

::: {.column width="50%"}

**First Difference**:

- Within treatment group over time
- Controls for time-invariant characteristics
- But confounded by time trends

**Second Difference**:

- Between the first differences
- Controls for time trends affecting both groups
- Isolates the treatment effect
:::

::: {.column width="50%"}
```{r, echo=FALSE}
library(knitr)

# Create DiD table
did_table <- data.frame(
  Group = c("Treatment", "Control", "Difference"),
  Before = c(40, 50, -10),
  After = c(30, 50, -20),
  Difference = c(-10, 0, -10)
)

kable(did_table, align = "lccc", caption = "DiD Calculation Example")
```

- Treatment effect = -10
:::

::::

## Program Case: DiD Setup

- We compare changes in waste expenditures for businesses offered the program vs. non-offered businesses
- Both groups are in treatment neighborhoods (where the program was offered)
- We have data for two periods: before and after the program implementation
- DiD can help address selection bias if trends would be parallel without the program

## Implementing DiD with Regression

```{r, eval=T, echo=TRUE}
# DiD regression without covariates
out_did <- lm_robust(waste_management_costs ~ round * intent_to_treat, 
                    data = df %>% filter(treatment_neighborhood == 1),
                    clusters = neighborhood_identifier)

# DiD regression with covariates
out_did_wcov <- lm_robust(waste_management_costs ~ round * intent_to_treat +
                         age_manager + age_deputy +
                  female_manager + foreign_owned + 
                  staff_size +
                  advanced_filtration + business_area +
                  recycling_center_distance, 
                       data = df %>% filter(treatment_neighborhood == 1),
                       clusters = neighborhood_identifier)
```

Where:

- `round`: Time indicator (0=before, 1=after)
- `intent_to_treat`: Treatment indicator (1=offered, 0=not offered)
- `round:intent_to_treat`: Interaction term capturing the DiD effect

## Interpreting DiD Regression Coefficients

In the model: $Y = \beta_0 + \beta_1 \text{Round} + \beta_2 \text{Offered} + \beta_3 (\text{Round} \times \text{Offered}) + \varepsilon$

:::: {.columns}

::: {.column width="50%"}
- $\beta_0$: Baseline outcome for non-offered group
- $\beta_1$: Time trend (change for non-offered)
- $\beta_2$: Baseline difference between groups
- $\beta_3$: **DiD estimate (treatment effect)**
:::

::: {.column width="50%"}
```{r, echo=FALSE}
library(knitr)

# Create coefficient interpretation table
coef_table <- data.frame(
  Period = c("Before (Round=0)", "After (Round=1)", "Difference"),
  Not_Offered = c("β₀", "β₀ + β₁", "β₁"),
  Offered = c("β₀ + β₂", "β₀ + β₁ + β₂ + β₃", "β₁ + β₃"),
  Difference = c("β₂", "β₂ + β₃", "β₃")
)

kable(coef_table, 
      col.names = c("Period", "Not Offered", "Offered", "Difference"),
      caption = "Interpretation of DiD Coefficients")
```
:::

::::

## Manually Calculating the Difference-in-Differences (DiD) Estimator

To build intuition for the regression-based approach, let’s compute the DiD estimator manually.  
The key idea: measure how outcomes changed over time for the treated group and for the control group,  
then take the **difference of those changes**.

# Step 1: Compute Mean Outcomes by Group and Period

```{r, eval=TRUE, echo=TRUE}

means <- df %>%
  filter(treatment_neighborhood == 1) %>%
  group_by(intent_to_treat, round) %>%
  summarise(mean_cost = mean(waste_management_costs, na.rm = TRUE)) %>%
  ungroup()

# means

# Mutate/reformat for table
mean_table <- means %>%
  mutate(intent_to_treat = ifelse(intent_to_treat == 1, "Offered", "Not Offered")) %>%
  pivot_wider(
  names_from = round,
  values_from = mean_cost,
  names_prefix = "round_"
  )

# Display neatly formatted table
kable(
  mean_table,
  col.names = c("Group", "Before (Round 0)", "After (Round 1)"),
  digits = 2,
  caption = "Mean Waste Management Costs Before and After Program by Group"
)


```

# Step 2: Compute Difference Across Periods for Each Group

```{r, eval=TRUE, echo=TRUE}

# Reshape means into a table and calculate change over time
mean_table <- mean_table %>%
  mutate(change = round_1 - round_0) # change over time for each group

# Compute differences in Offered − Not Offered
off_row <- mean_table %>% filter(intent_to_treat == "Offered")
ctrl_row <- mean_table %>% filter(intent_to_treat == "Not Offered")

before_diff <- off_row$round_0 - ctrl_row$round_0
after_diff  <- off_row$round_1 - ctrl_row$round_1

# Add rows underneath with the differences
final_table <- mean_table %>%
  add_row(
    intent_to_treat = "Change",
    round_0 = before_diff,
    round_1 = after_diff,
    change = as.numeric(NA)  
  )

# Display neatly formatted table
kable(
  final_table,
  col.names = c("Group", "Before (Round 0)", "After (Round 1)", "Change"),
  digits = 2,
  caption = "Mean Waste Management Costs and Differences (Before, After, and DiD)"
)

```

# Step 3: Compute Difference-in-Difference 

```{r, eval=TRUE, echo=TRUE}

did_manual <- diff(mean_table$change)
did_manual

```


## DiD Regression Results for the Program

:::: {.columns}

::: {.column width="50%"}
```{r, echo=FALSE}
library(knitr)

modelsummary(list("No covariate adj."= out_did, "With covariate adj." = out_did_wcov), stars = TRUE,
             gof_map = c("nobs", "r.squared","adj.r.squared"), output = 'kableExtra') %>%
  kable_styling(font_size = 13) 
```
::: 

```{r, echo=FALSE}

# ## Output for case study
# library(flextable)
# library(officer)
# 
# # Build the table as a flextable (editable in Word/PowerPoint)
# ft <- modelsummary(
#   list("DID" = out_did),
#   stars = TRUE,
#   gof_map = c("nobs"),
#   title = "DID Regression Results",
#   coef_map = c(
#     "round:intent_to_treat" = "DID Effect",
#     "round" = "Before vs. After",
#     "intent_to_treat" = "Offered vs. Not",
#     "(Intercept)" = "(Intercept)"
#   ),
#   notes = "Standard errors are in parentheses",
#   fmt = 2,
#   output = "flextable"
# )
# 
# # let flextable size to content, then stretch to a target width
# ft <- autofit(ft)
# ft <- fit_to_width(ft, max_width = 9)  # inches; ~content area on a PPT slide
# ft <- width(ft, j = 1, width = 2.5)    # widen the left/stub column (adjust as needed)
# 
# ## 1) Save to Word (.docx)
# doc <- read_docx()
# doc <- body_add_flextable(doc, ft)
# print(doc, target = "C:/Users/FionaKastel/OneDrive - 3ie/Documents/GitHub/R-course/sessions_in_Abu_Dhabi/case_study_outputs/session9_DID.docx")

``` 

::: {.column width="50%"}

**Interpretation**:

- Initial difference: Businesses offered the program spent AED `r round  (abs(out_did$coefficients[3]),1)` less at baseline
- Time trend: Non-offered businesses increased spending by AED `r round  (out_did$coefficients[2],1)`
- **Treatment effect**: Program reduced expenditures by AED `r round  (abs(out_did$coefficients[4]),1)`
- Result is statistically significant but below the 1,000 Dirham threshold

:::

::::

## Visualizing the DiD Result

```{r, echo=FALSE, fig.height=6.5}
# Extract values from model coefficients
beta0 <- out_did$coefficients["(Intercept)"]
beta1 <- out_did$coefficients["round"]
beta2 <- out_did$coefficients["intent_to_treat"]
beta3 <- out_did$coefficients["round:intent_to_treat"]

# Calculate cell values based on DiD model
not_offered_before <- beta0
not_offered_after <- beta0 + beta1
offered_before <- beta0 + beta2
offered_after <- beta0 + beta1 + beta2 + beta3

# Create data for DiD visualization
time_points <- c("Baseline", "Follow-up")
offered <- c(offered_before/1000, offered_after/1000)  # Converting to thousands
not_offered <- c(not_offered_before/1000, not_offered_after/1000)  # Converting to thousands

# Create data frame
did_viz_data <- data.frame(
  Time = rep(time_points, 2),
  Group = rep(c("Offered", "Not Offered"), each = 2),
  Expenditure = c(offered, not_offered)
)

# Calculate differences for annotations
diff_after <- not_offered_after/1000 - offered_after/1000
diff_before <- not_offered_before/1000 - offered_before/1000
diff_in_diff <- diff_after - diff_before

# Plot DiD
ggplot(did_viz_data, aes(x = Time, y = Expenditure, color = Group, group = Group)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  annotate("segment", x = 2, xend = 2, y = offered_after/1000, yend = not_offered_after/1000, 
           arrow = arrow(ends = "both", length = unit(0.1, "inches")), 
           linetype = "dashed") +
  annotate("text", x = 2.1, y = (offered_after/1000 + not_offered_after/1000)/2, 
           label = sprintf("%.2f", diff_after)) +
  annotate("segment", x = 1, xend = 1, y = offered_before/1000, yend = not_offered_before/1000, 
           arrow = arrow(ends = "both", length = unit(0.1, "inches")), 
           linetype = "dashed") +
  annotate("text", x = 1.1, y = (offered_before/1000 + not_offered_before/1000)/2, 
           label = sprintf("%.2f", diff_before)) +
  annotate("text", x = 1.5, y = min(offered, not_offered) - .2, 
           label = sprintf("Difference-in-Differences:\n%.2f - %.2f = %.2f", 
                          diff_after, diff_before, diff_in_diff), 
           fontface = "bold") +
  labs(title = "", x = "",
       y = "Waste Expenditures (thousands of AED)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


## The Parallel Trends Assumption

:::: {.columns}

::: {.column width="60%"}
The key identifying assumption in DiD:

> In the absence of treatment, the difference between treatment and control groups would remain constant over time

- Cannot be directly tested in the post-treatment period
- Can examine pre-treatment trends if multiple periods available
- Can also use placebo tests with different groups or outcomes
:::

::: {.column width="40%"}
```{r, echo=FALSE, fig.height=4}
library(ggplot2)

# Create data for parallel trends visualization
periods <- seq(1, 5)
treated_actual <- c(40, 40, 40, 30, 25)
treated_counterfactual <- c(40, 40, 40, 40, 40)
control <- c(50, 50, 50, 50, 50)

# Create data frame
trends_data <- data.frame(
  Period = rep(periods, 3),
  Group = c(rep("Treated (Actual)", 5), rep("Treated (Counterfactual)", 5), rep("Control", 5)),
  Value = c(treated_actual, treated_counterfactual, control)
)

# Plot parallel trends
ggplot(trends_data, aes(x = Period, y = Value, color = Group, linetype = Group)) +
  geom_line(size = 1) +
  geom_vline(xintercept = 3.5, linetype = "dashed") +
  annotate("text", x = 3.5, y = 55, label = "Treatment", hjust = -0.2) +
  annotate("rect", xmin = 3.5, xmax = 5, ymin = 25, ymax = 40, alpha = 0.1, fill = "blue") +
  annotate("text", x = 4.2, y = 35, label = "Treatment\nEffect", color = "blue") +
  scale_linetype_manual(values = c("Treated (Actual)" = "solid", 
                                   "Treated (Counterfactual)" = "dotted", 
                                   "Control" = "solid")) +
  labs(title = "Parallel Trends Assumption",
       y = "Outcome") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
:::

::::

## Threats to the Parallel Trends Assumption

1. **Differential time shocks**
   - Events affecting one group but not the other
   - Example: Other policies targeting the same population

2. **Compositional changes**
   - Changes in group makeup over time
   - Example: Selective migration or attrition

3. **Anticipation effects**
   - Behavior changes before treatment starts
   - Example: Postponing waste management in anticipation of subsidies

4. **Feedback effects**
   - Treatment affects the control group
   - Example: Spillovers or general equilibrium effects

## Testing Parallel Pre-Trends
:::: {.columns}

::: {.column width="40%"}

```{r, eval=T, echo=TRUE}
#| class: small-code

# Create simple dataset with 20 observations
did_data <- data.frame(
  # 4 time periods (0-3), treatment in period 2
  time = rep(0:3, 5),
  # 10 units (5 treated, 5 control)
  unit = rep(1:10, each = 4),
  # Treatment indicator
  treated = rep(c(rep(0, 5), rep(1, 5)), each = 4),
  # Period indicator (pre/post)
  post = rep(c(0,0,1,1), 10)
)

# Base outcome - parallel trends
did_data$y_parallel <- 10 + 2*did_data$time + 3*did_data$treated + 
                      5*(did_data$post*did_data$treated) + rnorm(40, 0, 1)

# Non-parallel trends
did_data$y_nonparallel <- did_data$y_parallel + 
                         2*did_data$time*did_data$treated



```

:::

::: {.column width="60%"}

```{r}
# Quick visual check of parallel trends
ggplot(did_data, aes(x = time, y = y_parallel, color = factor(treated), group = factor(treated))) +
  stat_summary(fun = mean, geom = "line") +
  stat_summary(fun = mean, geom = "point", size = 3) +
  geom_vline(xintercept = 1.5, linetype = "dashed") +
  labs(title = "Parallel Trends Example", x = "Time", y = "Outcome", color = "Treated") +
  theme_minimal()
```

:::

::::

## Variants of DiD

1. **Two-way fixed effects (TWFE)**
   ```r
   lm(outcome ~ treated*post + unit_fe + time_fe, data = data)
   ```

2. **Staggered adoption**
   - Treatment implemented at different times
   - Recent methods: Callaway & Sant'Anna, Sun & Abraham
   
3. **Triple differences (DDD)**
   - Additional comparison dimension
   - Further controls for potential confounders

4. **Synthetic control**
   - Weighted combination of control units
   - Data-driven approach to creating the counterfactual

## DiD vs. Other Methods

:::: {.columns}

::: {.column width="33%"}
**DiD**:

- Effect: -816 AED
- Uses longitudinal data
- Addresses selection bias
- Requires parallel trends

**Recommendation**:  
Do not scale up
:::

::: {.column width="33%"}
**RDD**:

- Effect: -905 AED
- Uses eligibility threshold
- Local to cutoff
- Sharp discontinuity

**Recommendation**:  
Do not scale up
:::

::: {.column width="33%"}
**Randomized**:

- Effect: -1,014 AED
- Gold standard
- Average effect
- Highest precision

**Recommendation**:  
Scale up nationally
:::

::::

**Why the difference with randomized results?**

- Selection bias not fully addressed by DiD
- Non-offered businesses may have different trends
- Parallel trends assumption may not hold

## When to Use DiD

**Use when**:

- Panel or repeated cross-sectional data available
- Pre-treatment data exists for both groups
- Parallel trends assumption is plausible
- Selection based on time-invariant factors

**Common applications**:

- Policy changes affecting some groups but not others
- Phased program implementation
- Natural experiments creating treatment/control groups

## Implementing DiD in R

```{r, eval=FALSE, echo=TRUE}
# Basic DiD implementation

# Step 1: Basic DiD regression
did_model <- lm(
  outcome ~ treatment*post + controls,
  data = data
)

# Step 2: With fixed effects
library(fixest)
did_fe <- feols(
  outcome ~ treatment*post | unit + time,
  data = data,
  cluster = "group_id"
)

# Step 3: Staggered adoption with modern methods
library(did)
staggered_did <- att_gt(
  yname = "outcome",
  tname = "time",
  idname = "id",
  gname = "first_treated",
  data = data
)
```

## Common Pitfalls in DiD Analysis

1. **Violation of parallel trends**
   - Most crucial assumption
   - Test with pre-treatment data when possible

2. **Serial correlation**
   - Outcomes correlated over time
   - Use clustered standard errors

3. **Improper handling of covariates**
   - Time-varying controls may be affected by treatment
   - Better to use baseline covariates interacted with time

4. **Heterogeneous treatment effects over time**
   - Effects that grow or fade
   - Consider event study design

## From Analysis to Policy Decision

**Policy question**: Should the program be scaled up nationally?

**Decision criterion**: Program must reduce businesses' expenditures by at least 1,000 AED.

**Results from DiD estimation**:

- Effect: `r round(out_did$coefficients[4],0)` (95% CI: [ `r round(out_did$coefficients[4] + 1.96*out_did$std.error[4],0)`, `r round(out_did$coefficients[4] - 1.96*out_did$std.error[4],0)`])
- Point estimate below the 1,000 AED threshold
- Effect robust to inclusion of covariates

**Recommendation**: Based on the DiD estimate, the program should not be scaled up nationally.

## Key Takeaways

1. DiD compares changes over time between treatment and control groups
2. DiD controls for time-invariant differences between groups
3. The key assumption is parallel trends in the absence of treatment
4. The Program reduced waste expenditures by `r round(abs(out_did$coefficients[4]),0)` according to DiD
5. This estimate is below the 1,000 AED threshold for scaling up nationally

## Next Session

**Matching Methods**: Creating comparable treatment and control groups based on observable characteristics